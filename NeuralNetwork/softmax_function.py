import numpy as np

# 기계학습 문제는 분류 또는 회귀로 나뉜다.
# 분류는 데이터가 어느 종류에 속하는가에 대한 문제이다. (사진 보고 성별, 종 구분)
# 회귀는 데이터의 수치를 예측하는 문제이다.

# 활성화 함수에는 계단 함수, 시그모이드 함수, ReLU 함수 등이 있었다. (ReLU 함수는 0 보다 작으면 0을, 크면 그 값을 그대로 출력하는 함수)
# 출력층에 쓰는 함수에는 항등 함수, 소프트맥스 함수가 있다.
# 일반적으로 분류에는 소프트맥스, 회귀에는 항등 함수를 쓴다.

# 소프트맥스 함수 구현하기

# 소프트맥스 함수는 x 란 입력값으로 e^x / (e^(x1) + e^(x2)...) 이란 결과를 내보낸다.

def softmaxFunction\
                (x):
    expA = np.exp(x)
    return expA / np.sum(np.exp(x))

# 단, 이는 컴퓨터로 계산할 때 매우 불안정하다.
# 100만 넘어도 10^40 이 되는 값이 되므로
# 로그를 취하여 계산 과정에서의 값이 오버플로우가 나지 않도록 해주자.

def softmax(x):
    c = np.max(x)
    x -= c
    expA = np.exp(x)
    return expA / np.sum(np.exp(x))

a = np.array([0.3, 2.9, 4.0])
y = softmax(a)

print(y)
print(np.sum(y)) # 소프트맥스 함수의 합은 1이 된다. 즉 확률의 성격을 띈다.
